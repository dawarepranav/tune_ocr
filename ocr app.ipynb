{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**switch to T4 gpu runtime before running**"
      ],
      "metadata": {
        "id": "UtjKtkrLwtZv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyx8TrezQM3F",
        "outputId": "4c8fbd88-c5cd-4e32-dd76-9fc0488525e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.44.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: verovio in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.7)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.12)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.6.8)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.31.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1.0->gradio) (0.38.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install gradio transformers accelerate verovio tiktoken Pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Load the model and tokenizer from local path\n",
        "# Assuming your model and tokenizer are stored in '/content/model' directory in Colab\n",
        "model_path = 'pranavdaware/web_ocr'\n",
        "\n",
        "# Load the model and tokenizer from the local directory\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
        "model = AutoModel.from_pretrained(model_path, trust_remote_code=True, low_cpu_mem_usage=True, device_map='cuda', use_safetensors=True)\n",
        "model = model.eval().cuda()\n",
        "\n",
        "# Function to extract text using OCR\n",
        "def ocr_processing(image_file):\n",
        "    try:\n",
        "        # Perform OCR on the uploaded image\n",
        "        result = model.chat(tokenizer, image_file, ocr_type='ocr')\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "# Function to search for keywords in extracted text\n",
        "def search_keyword(ocr_text, keyword):\n",
        "    try:\n",
        "        # Use regex to search for the keyword and highlight matches\n",
        "        matches = re.findall(rf\"({keyword})\", ocr_text, re.IGNORECASE)\n",
        "        if matches:\n",
        "            highlighted_text = re.sub(rf\"({keyword})\", r'<mark>\\1</mark>', ocr_text, flags=re.IGNORECASE)\n",
        "            return highlighted_text\n",
        "        else:\n",
        "            return f\"No matches found for '{keyword}' in the extracted text.\"\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "# Gradio interface\n",
        "def main():\n",
        "    # Gradio app layout\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# OCR and Keyword Search Application\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                image_input = gr.Image(type=\"filepath\", label=\"Upload your image\")\n",
        "                keyword_input = gr.Textbox(label=\"Enter keyword to search\")\n",
        "                ocr_output = gr.Textbox(label=\"OCR Output\")\n",
        "                search_output = gr.HTML(label=\"Search Results\")\n",
        "\n",
        "                # Button for OCR processing\n",
        "                process_button = gr.Button(\"Process Image for OCR\")\n",
        "\n",
        "                # Connect the OCR processing function to the button\n",
        "                process_button.click(\n",
        "                    fn=ocr_processing,\n",
        "                    inputs=image_input,\n",
        "                    outputs=ocr_output\n",
        "                )\n",
        "\n",
        "                # Button for keyword search\n",
        "                search_button = gr.Button(\"Search Keyword in OCR Text\")\n",
        "\n",
        "                # Connect the search function to the button\n",
        "                search_button.click(\n",
        "                    fn=search_keyword,\n",
        "                    inputs=[ocr_output, keyword_input],\n",
        "                    outputs=search_output\n",
        "                )\n",
        "\n",
        "    # Launch the Gradio demo\n",
        "    demo.launch()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "obuPmyVdQbbj",
        "outputId": "190a18de-8cf9-4360-b5ea-c00eb78d860a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://58694abdca92fd75af.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://58694abdca92fd75af.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessed images make them grayscale and size 900X64 ( as training images were of these size )"
      ],
      "metadata": {
        "id": "ywE5vrvRvwMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import os\n",
        "import re\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# Load the model and tokenizer from local path\n",
        "model_path = 'pranavdaware/web_ocr'\n",
        "\n",
        "# Load the model and tokenizer from the local directory\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
        "model = AutoModel.from_pretrained(model_path, trust_remote_code=True, low_cpu_mem_usage=True, device_map='cuda', use_safetensors=True)\n",
        "model = model.eval().cuda()\n",
        "\n",
        "# Function to preprocess the image (convert to black and white, resize)\n",
        "def preprocess_image(image_file):\n",
        "    try:\n",
        "        # Open image using PIL\n",
        "        image = Image.open(image_file)\n",
        "\n",
        "        # Convert the image to black and white\n",
        "        image_bw = ImageOps.grayscale(image)\n",
        "\n",
        "        # Resize the image to 900x64 pixels\n",
        "        image_resized = image_bw.resize((900, 64))\n",
        "\n",
        "        # Save the preprocessed image to pass to the OCR model\n",
        "        preprocessed_image_path = \"preprocessed_image.png\"\n",
        "        image_resized.save(preprocessed_image_path)\n",
        "\n",
        "        return preprocessed_image_path\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "# Function to extract text using OCR\n",
        "def ocr_processing(image_file):\n",
        "    try:\n",
        "        # Preprocess the image before OCR\n",
        "        preprocessed_image = preprocess_image(image_file)\n",
        "\n",
        "        # Perform OCR on the preprocessed image\n",
        "        result = model.chat(tokenizer, preprocessed_image, ocr_type='ocr')\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "# Function to search for keywords in extracted text\n",
        "def search_keyword(ocr_text, keyword):\n",
        "    try:\n",
        "        # Use regex to search for the keyword and highlight matches\n",
        "        matches = re.findall(rf\"({keyword})\", ocr_text, re.IGNORECASE)\n",
        "        if matches:\n",
        "            highlighted_text = re.sub(rf\"({keyword})\", r'<mark>\\1</mark>', ocr_text, flags=re.IGNORECASE)\n",
        "            return highlighted_text\n",
        "        else:\n",
        "            return f\"No matches found for '{keyword}' in the extracted text.\"\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "# Gradio interface\n",
        "def main():\n",
        "    # Gradio app layout\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# OCR and Keyword Search Application\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                image_input = gr.Image(type=\"filepath\", label=\"Upload your image\")\n",
        "                keyword_input = gr.Textbox(label=\"Enter keyword to search\")\n",
        "                ocr_output = gr.Textbox(label=\"OCR Output\")\n",
        "                search_output = gr.HTML(label=\"Search Results\")\n",
        "\n",
        "                # Button for OCR processing\n",
        "                process_button = gr.Button(\"Process Image for OCR\")\n",
        "\n",
        "                # Connect the OCR processing function to the button\n",
        "                process_button.click(\n",
        "                    fn=ocr_processing,\n",
        "                    inputs=image_input,\n",
        "                    outputs=ocr_output\n",
        "                )\n",
        "\n",
        "                # Button for keyword search\n",
        "                search_button = gr.Button(\"Search Keyword in OCR Text\")\n",
        "\n",
        "                # Connect the search function to the button\n",
        "                search_button.click(\n",
        "                    fn=search_keyword,\n",
        "                    inputs=[ocr_output, keyword_input],\n",
        "                    outputs=search_output\n",
        "                )\n",
        "\n",
        "    # Launch the Gradio demo\n",
        "    demo.launch()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "W3V9b1Ugo7O5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "9a70f728-3166-40a7-d07c-da835e3e5a76"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://8341e8ee308fd86a91.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8341e8ee308fd86a91.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}